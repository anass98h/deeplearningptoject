{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a1d2ae",
   "metadata": {},
   "source": [
    "## Deep Learning Steps - PoseNet\n",
    "Both scripts aim to detect exercise segments based on PoseNet data. They share several core steps:\n",
    "\n",
    "1. **Data Loading & Preprocessing**  \n",
    "   - Read full-pose CSV files and corresponding trimmed CSVs.  \n",
    "   - Smooth sequences via a moving-average window and compute deltas.  \n",
    "   - Derive labels indicating exercise frames vs. non-exercise frames.\n",
    "\n",
    "2. **Train/Test Split**  \n",
    "   - Group-based splitting ensures entire videos fall into either train or test.\n",
    "\n",
    "3. **Feature Scaling**  \n",
    "   - A `StandardScaler` is fit on training data only, then applied to both sets.\n",
    "\n",
    "4. **Model Definition & Training**  \n",
    "   - The first script trains an MLP classification model (using scikeras + GridSearchCV).  \n",
    "   - The second script handles two modes:  \n",
    "     - “frame” mode with a weighted-BCE loss per frame.  \n",
    "     - “boundary” mode using MSE on the normalized start/end positions.\n",
    "\n",
    "5. **Evaluation**  \n",
    "   - Compute frame-level metrics like precision, recall, F1, and boundary errors.  \n",
    "   - In the second script, boundary-mode evaluation checks how close predicted start/end match the ground-truth.\n",
    "\n",
    "###  Parameter Variations\n",
    "1. **First Script (postnetcutting.py)**  \n",
    "   - Tries a grid of MLP hyperparameters (hidden_units=256, hidden_layers=12, dropout_rate=0.30).  \n",
    "   - Uses up to 50 epochs and a batch size of 64.\n",
    "\n",
    "2. **Second Script (postnetcutting2.py)**  \n",
    "   - Selects number of layers (default 12) and hidden units (128).  \n",
    "   - Adjusts mode (“frame” / “boundary”) for loss function choice.  \n",
    "   - Configures distinct hyperparameters (dropout=0, LR=1e-4, batch size=256, epochs=50).\n",
    "\n",
    "### Results\n",
    "After training, the aggregate boundary error was:\n",
    "\n",
    "──────── Aggregate boundary error ────────\n",
    "\n",
    "Δstart mean +5.33 ± 25.88 median |Δ| 12.0 frames\n",
    "\n",
    "Δend mean -3.28 ± 21.89 median |Δ| 8.5 frames\n",
    "\n",
    "This indicates that on average, the model predicts start frames 5.33 frames later and end frames 3.28 frames earlier than the ground truth. The high standard deviations (25.88 and 21.89 frames) suggest considerable variability in predictions. The median absolute errors (12.0 for start, 8.5 for end) provide a more robust measure of typical error, less affected by outliers.\n",
    "\n",
    "\n",
    "## Deep Learning Steps - Kinect\n",
    "\n",
    "Regarding the kinectcutting.py, the following steps were taken:\n",
    "\n",
    "1. Data Loading and Preprocessing\n",
    "\n",
    "* Loads matched CSV files from uncut and preprocessed directories.\n",
    "* Applies data augmentation: mirroring and rotation (±15 degrees).\n",
    "* Creates sliding windows of 11 frames for input features.\n",
    "\n",
    "2. Data Splitting\n",
    "\n",
    "* Uses GroupShuffleSplit to ensure entire sequences remain in either train or test set.\n",
    "* 80% train, 20% test split.\n",
    "\n",
    "3. Feature Scaling\n",
    "\n",
    "* Applies StandardScaler to normalize input features.\n",
    "\n",
    "4. Model Architecture\n",
    "\n",
    "* Implements a sequential model with multiple dense layers.\n",
    "* Uses ReLU activation for hidden layers and sigmoid for output.\n",
    "* Compiles with binary cross-entropy loss and Adam optimizer.\n",
    "\n",
    "5. Hyperparameter Tuning\n",
    "\n",
    "* Utilizes GridSearchCV for hyperparameter optimization.\n",
    "* Searches over number of layers, units, learning rate, batch size, and epochs.\n",
    "\n",
    "6. Model Training\n",
    "\n",
    "* Trains the model using the best hyperparameters from GridSearchCV.\n",
    "* Implements early stopping to prevent overfitting.\n",
    "\n",
    "7. Evaluation\n",
    "\n",
    "* Evaluates on test set for loss, accuracy, precision, and recall.\n",
    "* Performs detailed boundary error analysis per video.\n",
    "\n",
    "### Parameter Variations\n",
    "The script explores the following hyperparameter space:\n",
    "\n",
    "* Number of layers: [12]\n",
    "* Number of units per layer: [128]\n",
    "* Learning rate: [1e-4]\n",
    "* Batch size: [128]\n",
    "* Number of epochs: [50]\n",
    "* Early stopping is implemented with a patience of 5 epochs, monitoring validation loss.\n",
    "\n",
    "### Result\n",
    "\n",
    "───────── Aggregate boundary error ─────────\n",
    "\n",
    "Δstart  mean  +2.83 ± 19.14   median |Δ| 5.0 frames\n",
    "\n",
    "Δend    mean  +1.22 ± 16.01   median |Δ| 3.0 frames\n",
    "\n",
    "### These results indicate:\n",
    "\n",
    "Start frames are predicted, on average, 2.83 frames later than actual.\n",
    "End frames are predicted, on average, 1.22 frames later than actual.\n",
    "The median absolute errors (5.0 for start, 3.0 for end) suggest relatively good accuracy in boundary detection.\n",
    "Standard deviations (19.14 for start, 16.01 for end) indicate some variability in predictions.\n",
    "Overall, the model shows promising performance in detecting exercise segment boundaries, with slightly better accuracy for end frames compared to start frames.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7adf514",
   "metadata": {},
   "source": [
    "## Software development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94181bf",
   "metadata": {},
   "source": [
    "# Frame Trimmer Implementation Progress Report\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "We have successfully implemented the Frame Trimmer component for the ML Prediction Dashboard that allows users to:\n",
    "\n",
    "1. Upload CSV files containing skeletal keypoint data\n",
    "2. Send the CSV to the backend for frame trimming\n",
    "3. Visualize both the original and trimmed data in a side-by-side 3D comparison\n",
    "4. Clearly see which frames were kept vs. removed during the trimming process\n",
    "\n",
    "The Frame Trimmer has been integrated as a new tab in the existing dashboard alongside the \"Predictions\" and \"PoseNet\" tabs.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "### Frontend Components\n",
    "\n",
    "1. **FrameTrimmer.jsx**\n",
    "   - Main component that handles file upload, processing, and visualization\n",
    "   - Integrated with the existing SkeletonContext and SkeletonRenderer components\n",
    "   - Includes a visual timeline showing which frames were kept vs. removed\n",
    "   - Implements custom playback controls that handle all frames\n",
    "\n",
    "2. **Custom Animation and Controls**\n",
    "   - Replaced the standard AnimationManager with a custom implementation\n",
    "   - Created custom controls to properly handle the original frame count\n",
    "   - Fixed issues with playback that previously stopped at the end of trimmed data\n",
    "\n",
    "3. **Visual Frame Timeline**\n",
    "   - Implemented a series of colored div elements to create a timeline\n",
    "   - Green segments show frames that were kept in the trimmed dataset\n",
    "   - Red segments show frames that were removed\n",
    "   - Interactive elements allow users to click to jump to specific frames\n",
    "   - Optimized for performance with large datasets by implementing frame sampling\n",
    "\n",
    "### Backend Endpoint\n",
    "\n",
    "1. **`/trim-frames` Endpoint**\n",
    "   - Added a new POST endpoint to the FastAPI application\n",
    "   - Accepts a CSV file and returns a trimmed version\n",
    "   - Currently returns a pre-trimmed output.csv file using our model(manually, without the pipeline) for testing\n",
    "   - Returns the CSV content directly as text\n",
    "\n",
    "## Technical Challenges and Interim Solutions\n",
    "\n",
    "### Backend Processing Issues\n",
    "\n",
    "1. **Temporary Manual Workflow**\n",
    "   - **IMPORTANT NOTE:** Due to time constraints and the need to deliver a functional demonstration, we've established a temporary manual workflow:\n",
    "     1. Manually preprocess CSV files using the working script\n",
    "     2. Upload the processed files to the test folder of the backend\n",
    "     3. Compare the uploaded uncut data with the manually prepared trimmed data(uncut.csv can also be found in the backend folder)\n",
    "   - This approach allows us to showcase the functionality while we address the backend processing issues\n",
    "\n",
    "\n",
    "\n",
    "## User Experience Improvements\n",
    "\n",
    "1. **Intuitive Visualization**\n",
    "   - Color-coded timeline provides immediate visual feedback on trimmed frames\n",
    "   - Clear indicators show which frames were kept vs. removed\n",
    "   - Empty placeholder for removed frames clearly communicates when a frame was trimmed\n",
    "\n",
    "2. **Feedback and Status**\n",
    "   - Added informative badges showing frame counts and percentage removed\n",
    "   - Included status indicators to show current frame in both datasets\n",
    "   - Added an informative badge explaining the color coding\n",
    "\n",
    "3. **Responsive Controls**\n",
    "   - Implemented smooth playback controls\n",
    "   - Added interactive timeline with click-to-seek functionality\n",
    "   - Ensured responsive design for different screen sizes\n",
    "\n",
    "## Technical Architecture\n",
    "\n",
    "The Frame Trimmer follows a clean architecture pattern:\n",
    "\n",
    "1. **Data Flow**\n",
    "   - User uploads CSV file → Frontend parses and displays original data\n",
    "   - CSV is sent to backend → Backend processes and returns trimmed data\n",
    "   - Frontend parses trimmed data → Both datasets visualized side by side\n",
    "\n",
    "2. **State Management**\n",
    "   - Uses React useState for component-level state\n",
    "   - Leverages SkeletonContext for shared visualization state\n",
    "   - Maintains mapping between original and trimmed frames\n",
    "\n",
    "3. **Optimization Techniques**\n",
    "   - Memoization of expensive calculations with useMemo\n",
    "   - Callback optimization with useCallback\n",
    "   - Conditional rendering to reduce DOM elements\n",
    "   - Sampling for large datasets to maintain performance\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Despite the backend processing challenges, the Frame Trimmer component successfully integrates with the existing ML Prediction Dashboard, providing a powerful tool for visualizing frame trimming results. The current manual workflow is a temporary solution that allows us to demonstrate the functionality while we work on fixing the backend issues."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
